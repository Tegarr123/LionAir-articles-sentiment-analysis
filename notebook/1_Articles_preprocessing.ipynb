{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47bb029e",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2774abdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (0.19.0)\n",
      "Requirement already satisfied: wordcloud in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (1.9.4)\n",
      "Requirement already satisfied: Sastrawi in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (1.0.1)\n",
      "Requirement already satisfied: nltk>=3.9 in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from textblob) (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /home/fadhinotgr/.local/lib/python3.13/site-packages (from wordcloud) (2.2.6)\n",
      "Requirement already satisfied: pillow in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from wordcloud) (11.3.0)\n",
      "Requirement already satisfied: matplotlib in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from wordcloud) (3.10.6)\n",
      "Requirement already satisfied: click in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from nltk>=3.9->textblob) (8.2.1)\n",
      "Requirement already satisfied: joblib in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from nltk>=3.9->textblob) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from nltk>=3.9->textblob) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from matplotlib->wordcloud) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from matplotlib->wordcloud) (4.60.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from matplotlib->wordcloud) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from matplotlib->wordcloud) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/fadhinotgr/.local/lib/python3.13/site-packages (from matplotlib->wordcloud) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/fadhinotgr/miniconda3/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob wordcloud Sastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593ec956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/fadhinotgr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/fadhinotgr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/fadhinotgr/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import string\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from deep_translator import GoogleTranslator\n",
    "import time\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e63e7",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5455104c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kategori</th>\n",
       "      <th>Link</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finance</td>\n",
       "      <td>https://industri.kontan.co.id/news/pemerintah-...</td>\n",
       "      <td>Pemerintah Resmi Turunkan Harga Tiket Pesawat,...</td>\n",
       "      <td>Reporter: Leni Wandira | Editor: Wahyu T.Rahma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Incident</td>\n",
       "      <td>https://news.okezone.com/read/2023/10/29/337/2...</td>\n",
       "      <td>Peristiwa 29 Oktober : Pesawat Lion Air Jatuh ...</td>\n",
       "      <td>SEJUMLAH peristiwa terjadi pada 29 Oktober. Sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Incident</td>\n",
       "      <td>https://www.cnnindonesia.com/ekonomi/202306081...</td>\n",
       "      <td>Deret Masalah Penerbangan Lion Air Group Sepan...</td>\n",
       "      <td>Sekretaris Umum PP Muhammadiyah Abdul Mu'ti me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Incident</td>\n",
       "      <td>https://www.antaranews.com/video/3366141/ini-d...</td>\n",
       "      <td>Ini dugaan penyebab kecelakaan pesawat Lion Ai...</td>\n",
       "      <td>Copyright © ANTARA 2023\\nDilarang keras mengam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Operational</td>\n",
       "      <td>https://haji.kemenag.go.id/v5/detail/tingkatka...</td>\n",
       "      <td>Tingkatkan Kualitas Layanan, Kemenag - Lion Ai...</td>\n",
       "      <td>21 Feb 2025 oleh Husni Anggoro | dilihat 42259...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Kategori                                               Link  \\\n",
       "0      Finance  https://industri.kontan.co.id/news/pemerintah-...   \n",
       "1     Incident  https://news.okezone.com/read/2023/10/29/337/2...   \n",
       "2     Incident  https://www.cnnindonesia.com/ekonomi/202306081...   \n",
       "3     Incident  https://www.antaranews.com/video/3366141/ini-d...   \n",
       "4  Operational  https://haji.kemenag.go.id/v5/detail/tingkatka...   \n",
       "\n",
       "                                       article_title  \\\n",
       "0  Pemerintah Resmi Turunkan Harga Tiket Pesawat,...   \n",
       "1  Peristiwa 29 Oktober : Pesawat Lion Air Jatuh ...   \n",
       "2  Deret Masalah Penerbangan Lion Air Group Sepan...   \n",
       "3  Ini dugaan penyebab kecelakaan pesawat Lion Ai...   \n",
       "4  Tingkatkan Kualitas Layanan, Kemenag - Lion Ai...   \n",
       "\n",
       "                                        article_text  \n",
       "0  Reporter: Leni Wandira | Editor: Wahyu T.Rahma...  \n",
       "1  SEJUMLAH peristiwa terjadi pada 29 Oktober. Sa...  \n",
       "2  Sekretaris Umum PP Muhammadiyah Abdul Mu'ti me...  \n",
       "3  Copyright © ANTARA 2023\\nDilarang keras mengam...  \n",
       "4  21 Feb 2025 oleh Husni Anggoro | dilihat 42259...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pd.read_csv(\"data/articles_raw.csv\")\n",
    "df_articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b9e8f",
   "metadata": {},
   "source": [
    "### Clear up article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11f1e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain(text:str):\n",
    "    x = text.replace(\"https://\", \"\")\n",
    "    x = x.split(\"/\")[0]\n",
    "    x = re.sub(r\"www\\.|\\.com|\\.co\\.id|\\.id|\\.co|\\.go\\.id|\\.asia\", \"\", x)\n",
    "    x = x if len(x.split(\".\")) < 2 else x.split(\".\")[1]\n",
    "    return x\n",
    "    \n",
    "\n",
    "df_articles['domain'] = df_articles['Link'].apply(get_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40cec685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_9999/2358987355.py:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"Baca Juga\\s?:\",\n"
     ]
    }
   ],
   "source": [
    "def cleanup_article(text):\n",
    "    contains = [\"Cek Berita dan Artikel yang\", \n",
    "                \"Baca Juga\\s?:\", \n",
    "                \"Reporter:\", \n",
    "                \"Sumber:\",\n",
    "                \"Nyaman tanpa iklan. \",\n",
    "                \"Ringkasan ini dibantu dengan menggunakan AI\",\n",
    "                \"SCROLL TO CONTINUE WITH CONTENT\",\n",
    "                \"Sumber gambar, \",\n",
    "                \"BELUM ADA KOMENTAR\",\n",
    "                \"DOKUMENTASI GAMBAR BELUM TERSEDIA\",\n",
    "                \"Telp. \",\n",
    "                \"Hak Cipta ©\",\n",
    "                \"Cobain For You Page\",\n",
    "                \"ADVERTISEMENT\",\n",
    "                \"Comment *\",\n",
    "                \"Name *\",\n",
    "                \"Email *\",\n",
    "                \"Baca berita dengan sedikit iklan\",\n",
    "                \"All Rights Reserved\",\n",
    "                \"Sekam Api Reformasi Polri\",\n",
    "                \"Scroll ke bawah\",\n",
    "                \"Jangan lupa klik di sini\",\n",
    "                \"Gambas:Video\",\n",
    "                \"Copyright ©\",\n",
    "                \"(Lihat|Simak) juga Video:\",\n",
    "                \"Simak juga '\",\n",
    "                \"Editor : \",\n",
    "                \"News dan WA Channel\",\n",
    "                \"CLICK HERE!\",\n",
    "                \"© 2025 BBC\",\n",
    "                \"Gabung Tempo Circle\",\n",
    "                \"Home » Investasi\",\n",
    "                \"(evs)\",\n",
    "                \"Lihat Video \",\n",
    "                \"Baca:\\xa0\",\n",
    "                \"Mau notif berita penting & breaking news\",\n",
    "                \"Jelajahi info seputar haji\",\n",
    "                \"Jurnalis :\",\n",
    "                \"PODCAST REKOMENDASI TEMPO \",\n",
    "                \"© 2023 \",\n",
    "                \"Copyright RRI.co.id.\",\n",
    "                \"Komentar menjadi tanggung-jawab Anda sesuai UU ITE.\",\n",
    "                \"Penulis: \"]\n",
    "    for c in contains: text = re.sub(rf\"(\\n|\\b).*{c}.*(\\n|\\b)\", \"\\n\", text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "df_articles['cleaned_article_text'] = df_articles['article_text'].apply(cleanup_article)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4024673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_space(text:str):\n",
    "    text_split = text.split(\"\\n\")\n",
    "    without_space_split = list(filter(lambda x : x.count(\" \") > 2, text_split))\n",
    "    without_space_split = list(map(lambda x : re.sub(r\"\\s+\", \" \", x), without_space_split))\n",
    "    cleaned_join = \"\\n\".join(without_space_split)\n",
    "    return cleaned_join\n",
    "df_articles['cleaned_article_text'] = df_articles['cleaned_article_text'].apply(clean_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "709c8df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "\n",
    "import random\n",
    "itg = random.randint(0, 152)\n",
    "df_articles.loc[itg, \"article_text\"].split(\"\\n\"), df_articles.loc[itg, \"cleaned_article_text\"].split(\"\\n\") \n",
    "\n",
    "with open(\"article_text.txt\", \"w\") as file:\n",
    "    file.write(df_articles.loc[itg, \"article_text\"])\n",
    "    \n",
    "with open(\"cleaned_article_text.txt\", \"w\")as file:\n",
    "    file.write(df_articles.loc[itg, \"cleaned_article_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fb00e0",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30f3f2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Kategori                                               Link  \\\n",
      "0      Finance  https://industri.kontan.co.id/news/pemerintah-...   \n",
      "1     Incident  https://news.okezone.com/read/2023/10/29/337/2...   \n",
      "2     Incident  https://www.cnnindonesia.com/ekonomi/202306081...   \n",
      "3     Incident  https://www.antaranews.com/video/3366141/ini-d...   \n",
      "4  Operational  https://haji.kemenag.go.id/v5/detail/tingkatka...   \n",
      "\n",
      "                                       article_title  \\\n",
      "0  Pemerintah Resmi Turunkan Harga Tiket Pesawat,...   \n",
      "1  Peristiwa 29 Oktober : Pesawat Lion Air Jatuh ...   \n",
      "2  Deret Masalah Penerbangan Lion Air Group Sepan...   \n",
      "3  Ini dugaan penyebab kecelakaan pesawat Lion Ai...   \n",
      "4  Tingkatkan Kualitas Layanan, Kemenag - Lion Ai...   \n",
      "\n",
      "                                        article_text        domain  \\\n",
      "0  Reporter: Leni Wandira | Editor: Wahyu T.Rahma...        kontan   \n",
      "1  SEJUMLAH peristiwa terjadi pada 29 Oktober. Sa...       okezone   \n",
      "2  Sekretaris Umum PP Muhammadiyah Abdul Mu'ti me...  cnnindonesia   \n",
      "3  Copyright © ANTARA 2023\\nDilarang keras mengam...    antaranews   \n",
      "4  21 Feb 2025 oleh Husni Anggoro | dilihat 42259...       kemenag   \n",
      "\n",
      "                                cleaned_article_text  \n",
      "0  KONTAN.CO.ID - JAKARTA. Lion Group mendukung p...  \n",
      "1  SEJUMLAH peristiwa terjadi pada 29 Oktober. Sa...  \n",
      "2  Sekretaris Umum PP Muhammadiyah Abdul Mu'ti me...  \n",
      "3  Dilarang keras mengambil konten, melakukan cra...  \n",
      "4  21 Feb 2025 oleh Husni Anggoro | dilihat 42259...  \n"
     ]
    }
   ],
   "source": [
    "df_articles.dropna(subset=['cleaned_article_text'], inplace=True)\n",
    "df_articles['cleaned_article_text'] = df_articles['cleaned_article_text'].astype(str)\n",
    "\n",
    "print(df_articles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1271de10",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3a7ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Hapus URL\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    # Hapus Mention\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Hapus Angka\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Hapus Tanda Baca\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2de8e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles['cleaned_article_text'] = df_articles['cleaned_article_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b32dad8",
   "metadata": {},
   "source": [
    "### Sentiment Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97faab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                cleaned_article_text  polarity  subjectivity\n",
      "0  kontancoid  jakarta lion group mendukung penuh...  0.089297      0.302210\n",
      "1  sejumlah peristiwa terjadi pada  oktober salah...  0.134921      0.250794\n",
      "2  sekretaris umum pp muhammadiyah abdul muti men...  0.033559      0.340945\n",
      "3  dilarang keras mengambil konten melakukan craw...  0.000000      0.000000\n",
      "4   feb  oleh husni anggoro  dilihat  kali\\njakar...  0.144516      0.421348\n"
     ]
    }
   ],
   "source": [
    "def analyze_long_text_sentiment(text):\n",
    "    # Jika teksnya pendek, langsung proses\n",
    "    if len(text) < 5000:\n",
    "        try:\n",
    "            translated_text = GoogleTranslator(source='id', target='en').translate(text)\n",
    "            blob = TextBlob(translated_text)\n",
    "            return pd.Series([blob.sentiment.polarity, blob.sentiment.subjectivity])\n",
    "        except Exception as e:\n",
    "            print(f\"Terjadi error pada teks pendek: {e}\")\n",
    "            return pd.Series([None, None])\n",
    "\n",
    "    # Jika teks panjang, pecah menjadi beberapa bagian\n",
    "    else:\n",
    "        try:\n",
    "            max_chunk_size = 4500\n",
    "            chunks = [text[i:i+max_chunk_size] for i in range(0, len(text), max_chunk_size)]\n",
    "\n",
    "            translated_chunks = []\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                time.sleep(0.5)\n",
    "                translated_chunks.append(\n",
    "                    GoogleTranslator(source='id', target='en').translate(chunk)\n",
    "                )\n",
    "\n",
    "            # Gabungkan kembali semua hasil terjemahan\n",
    "            full_translated_text = ' '.join(translated_chunks)\n",
    "\n",
    "            # Analisis sentimen dari teks lengkap yang sudah diterjemahkan\n",
    "            blob = TextBlob(full_translated_text)\n",
    "            return pd.Series([blob.sentiment.polarity, blob.sentiment.subjectivity])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Terjadi error pada saat memproses teks panjang: {e}\")\n",
    "            return pd.Series([None, None])\n",
    "df_articles[['polarity', 'subjectivity']] = df_articles['cleaned_article_text'].apply(analyze_long_text_sentiment)\n",
    "\n",
    "print(df_articles[['cleaned_article_text', 'polarity', 'subjectivity']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e26dd21",
   "metadata": {},
   "source": [
    "### tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "276cb673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6653977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles['tokens'] = df_articles['cleaned_article_text'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b1128c",
   "metadata": {},
   "source": [
    "### Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d638d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stopwords = stopwords.words('indonesian')\n",
    "\n",
    "def remove_stopwords(tokens, stopwords_list):\n",
    "    return [word for word in tokens if word not in stopwords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3aa7a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles['tokens_no_stop'] = df_articles['tokens'].apply(lambda x: remove_stopwords(x, list_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ec60754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame setelah cleaning, tokenisasi, dan penghapusan stopword awal:\n",
      "                                cleaned_article_text  \\\n",
      "0  kontancoid  jakarta lion group mendukung penuh...   \n",
      "1  sejumlah peristiwa terjadi pada  oktober salah...   \n",
      "2  sekretaris umum pp muhammadiyah abdul muti men...   \n",
      "3  dilarang keras mengambil konten melakukan craw...   \n",
      "4   feb  oleh husni anggoro  dilihat  kali\\njakar...   \n",
      "\n",
      "                                      tokens_no_stop  \n",
      "0  [kontancoid, jakarta, lion, group, mendukung, ...  \n",
      "1  [peristiwa, oktober, salah, satunya, jatuhnya,...  \n",
      "2  [sekretaris, pp, muhammadiyah, abdul, muti, me...  \n",
      "3  [dilarang, keras, mengambil, konten, crawling,...  \n",
      "4  [feb, husni, anggoro, kali, jakarta, phu, dire...  \n",
      "\n",
      "20 Kata Paling Umum:\n",
      "[('pesawat', 1031), ('lion', 953), ('air', 952), ('penerbangan', 601), ('penumpang', 544), ('bandara', 438), ('danang', 241), ('maskapai', 209), ('udara', 207), ('jt', 205), ('september', 180), ('rute', 160), ('indonesia', 156), ('pilot', 146), ('bagasi', 145), ('group', 135), ('terbang', 126), ('jakarta', 123), ('”', 119), ('wib', 118)]\n"
     ]
    }
   ],
   "source": [
    "# Hapus stopwords default\n",
    "print(\"\\nDataFrame setelah cleaning, tokenisasi, dan penghapusan stopword awal:\")\n",
    "print(df_articles[['cleaned_article_text', 'tokens_no_stop']].head())\n",
    "\n",
    "all_tokens = [word for tokens in df_articles['tokens_no_stop'] for word in tokens]\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "freq_dist = FreqDist(all_tokens)\n",
    "\n",
    "print(\"\\n20 Kata Paling Umum:\")\n",
    "print(freq_dist.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7438be27",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4ca21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def stem_text(tokens):\n",
    "    return [stemmer.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5c84ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stopwords = ['klik']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c56f3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Hasil Akhir Setelah Custom Stopword & Stemming:\n",
      "                                cleaned_article_text  \\\n",
      "0  kontancoid  jakarta lion group mendukung penuh...   \n",
      "1  sejumlah peristiwa terjadi pada  oktober salah...   \n",
      "2  sekretaris umum pp muhammadiyah abdul muti men...   \n",
      "3  dilarang keras mengambil konten melakukan craw...   \n",
      "4   feb  oleh husni anggoro  dilihat  kali\\njakar...   \n",
      "\n",
      "                                      tokens_stemmed  \n",
      "0  [kontancoid, jakarta, lion, group, dukung, pen...  \n",
      "1  [peristiwa, oktober, salah, satu, jatuh, pesaw...  \n",
      "2  [sekretaris, pp, muhammadiyah, abdul, muti, kr...  \n",
      "3  [larang, keras, ambil, konten, crawling, indek...  \n",
      "4  [feb, husni, anggoro, kali, jakarta, phu, dire...  \n",
      "\n",
      "Kolom Teks Final (String):\n",
      "                                cleaned_article_text  \\\n",
      "0  kontancoid  jakarta lion group mendukung penuh...   \n",
      "1  sejumlah peristiwa terjadi pada  oktober salah...   \n",
      "2  sekretaris umum pp muhammadiyah abdul muti men...   \n",
      "3  dilarang keras mengambil konten melakukan craw...   \n",
      "4   feb  oleh husni anggoro  dilihat  kali\\njakar...   \n",
      "\n",
      "                                          text_final  \n",
      "0  kontancoid jakarta lion group dukung penuh bij...  \n",
      "1  peristiwa oktober salah satu jatuh pesawat lio...  \n",
      "2  sekretaris pp muhammadiyah abdul muti kritik p...  \n",
      "3  larang keras ambil konten crawling indeks otom...  \n",
      "4  feb husni anggoro kali jakarta phu direktorat ...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_stopwords = list_stopwords + custom_stopwords\n",
    "\n",
    "df_articles['tokens_final'] = df_articles['tokens'].apply(lambda x: remove_stopwords(x, final_stopwords))\n",
    "\n",
    "df_articles['tokens_stemmed'] = df_articles['tokens_final'].apply(stem_text)\n",
    "\n",
    "print(\"\\nDataFrame Hasil Akhir Setelah Custom Stopword & Stemming:\")\n",
    "# Tampilkan kolom-kolom relevan untuk perbandingan\n",
    "print(df_articles[['cleaned_article_text', 'tokens_stemmed']].head())\n",
    "\n",
    "# Anda juga bisa menyimpan hasil akhir sebagai string jika diperlukan\n",
    "df_articles['text_final'] = df_articles['tokens_stemmed'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "print(\"\\nKolom Teks Final (String):\")\n",
    "print(df_articles[['cleaned_article_text', 'text_final']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e339fc",
   "metadata": {},
   "source": [
    "### Sentiment Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43d22442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame dengan kolom label sentimen baru:\n",
      "                                        article_text  polarity sentiment_label\n",
      "0  Reporter: Leni Wandira | Editor: Wahyu T.Rahma...  0.089297        Positive\n",
      "1  SEJUMLAH peristiwa terjadi pada 29 Oktober. Sa...  0.134921        Positive\n",
      "2  Sekretaris Umum PP Muhammadiyah Abdul Mu'ti me...  0.033559          Netral\n",
      "3  Copyright © ANTARA 2023\\nDilarang keras mengam...  0.000000          Netral\n",
      "4  21 Feb 2025 oleh Husni Anggoro | dilihat 42259...  0.144516        Positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9999/3079956587.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_articles['polarity'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def get_sentiment_label_from_polarity(polarity):\n",
    "    if polarity > 0.05:\n",
    "        return 'Positive'\n",
    "    elif polarity < -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Netral'\n",
    "\n",
    "df_articles['polarity'].fillna(0, inplace=True)\n",
    "df_articles['sentiment_label'] = df_articles['polarity'].apply(get_sentiment_label_from_polarity)\n",
    "\n",
    "print(\"DataFrame dengan kolom label sentimen baru:\")\n",
    "print(df_articles[['article_text', 'polarity', 'sentiment_label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57464136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles.to_csv(\"data/cleaned_article2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
